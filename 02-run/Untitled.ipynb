{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bae5f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48782193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25508218",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mswyft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msl\u001b[39;00m\n",
      "File \u001b[0;32m~/density/swyft/swyft/lightning/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswyft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/density/swyft/swyft/lightning/components.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mswyft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mswyft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarginalratioestimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_ntrain_nvalid\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzarr\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasteners\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "import swyft.lightning as sl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa07e69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpylab\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import swyft.lightning as sl\n",
    "import torch\n",
    "from lensx.logging_utils import log_post_plots, log_target_plots, log_train_plots\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# plt.switch_backend(\"agg\")\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d61e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"config_uniform_norm_blobs.yaml\")\n",
    "from lensx.nn.subN.plot import plt_imshow\n",
    "imkwargs = dict(extent=(-2.5, 2.5, -2.5, 2.5), origin='lower') #left, right, bottom, top\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import matplotlib.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(cfg):\n",
    "    # Loading simulator (potentially bounded)\n",
    "    simulator = hydra.utils.instantiate(cfg.simulation.model)\n",
    "\n",
    "    # Generate or load training data & generate datamodule\n",
    "    train_samples = sl.file_cache(\n",
    "        lambda: simulator.sample(cfg.simulation.store.store_size),\n",
    "        cfg.simulation.store.path,\n",
    "    )[: cfg.simulation.store.train_size]\n",
    "    datamodule = sl.SwyftDataModule(\n",
    "        store=train_samples,\n",
    "        model=simulator,  # Adds noise on the fly. `None` uses noise in store.\n",
    "        batch_size=cfg.estimation.batch_size,\n",
    "        num_workers=cfg.estimation.num_workers,\n",
    "    )\n",
    "\n",
    "    return datamodule, simulator\n",
    "\n",
    "def load(cfg, simulator):\n",
    "    print('Loading trained network')\n",
    "    tbl = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=cfg.tensorboard.save_dir,\n",
    "        name=cfg.tensorboard.name,\n",
    "        version=cfg.tensorboard.version,\n",
    "        default_hp_metric=False,\n",
    "    )\n",
    "    logdir = (\n",
    "        tbl.experiment.get_logdir()\n",
    "    )  # Directory where all logging information and checkpoints etc are stored\n",
    "    \n",
    "    checkpoints = os.listdir( os.path.join(logdir, 'checkpoint') )\n",
    "    if 'best.ckpt' in checkpoints:\n",
    "        best_ckpt = 'best.ckpt'\n",
    "    else:\n",
    "        best_idx = np.argmax(list(map(int, [checkpoint[6:8] for checkpoint in checkpoints])))\n",
    "        best_ckpt = checkpoints[best_idx]\n",
    "    print(f'best checkpoint is {best_ckpt}')\n",
    "    \n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(logdir, f'checkpoint/{best_ckpt}'), map_location='cpu'\n",
    "    )\n",
    "\n",
    "    network = hydra.utils.instantiate(cfg.estimation.network, cfg)\n",
    "    network.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    train_samples = torch.load(cfg.simulation.store.path)\n",
    "    \n",
    "    trainer = sl.SwyftTrainer(accelerator=cfg.estimation.accelerator, gpus=1)\n",
    "    trainer.setup(None)\n",
    "    \n",
    "    datamodule = sl.SwyftDataModule(store=train_samples, model=simulator)\n",
    "    datamodule.setup()\n",
    "    \n",
    "    trainer.model = network\n",
    "    \n",
    "    return network, trainer, tbl, datamodule\n",
    "\n",
    "def analyse(cfg, datamodule):\n",
    "    # Setting up tensorboard logger, which defines also logdir (contains trained network)\n",
    "    tbl = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=cfg.tensorboard.save_dir,\n",
    "        name=cfg.tensorboard.name,\n",
    "        version=cfg.tensorboard.version,\n",
    "        default_hp_metric=False,\n",
    "    )\n",
    "    logdir = (\n",
    "        tbl.experiment.get_logdir()\n",
    "    )  # Directory where all logging information and checkpoints etc are stored\n",
    "\n",
    "    # Load network and train (or re-load trained network)\n",
    "    network = hydra.utils.instantiate(cfg.estimation.network, cfg)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=cfg.estimation.early_stopping.min_delta,\n",
    "        patience=cfg.estimation.early_stopping.patience,\n",
    "        verbose=False,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=logdir + \"/checkpoint/\",\n",
    "        filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    trainer = sl.SwyftTrainer(\n",
    "        accelerator=cfg.estimation.accelerator,\n",
    "        gpus=1,\n",
    "        max_epochs=cfg.estimation.max_epochs,\n",
    "        logger=tbl,\n",
    "        callbacks=[lr_monitor, early_stop_callback, checkpoint_callback],\n",
    "    )\n",
    "    best_checkpoint = logdir + \"/checkpoint/best.ckpt\"\n",
    "    if not os.path.isfile(best_checkpoint):\n",
    "        trainer.fit(network, datamodule)\n",
    "        shutil.copy(checkpoint_callback.best_model_path, best_checkpoint)\n",
    "        trainer.test(network, datamodule)\n",
    "    else:\n",
    "        trainer.fit(network, datamodule, ckpt_path=best_checkpoint)\n",
    "\n",
    "    return network, trainer, tbl\n",
    "\n",
    "\n",
    "def interpret(cfg, simulator, network, trainer, datamodule, tbl):\n",
    "    hydra.utils.call(\n",
    "        cfg.inference.interpreter, cfg, simulator, network, trainer, datamodule, tbl\n",
    "    )\n",
    "\n",
    "@hydra.main(config_path=\".\", config_name=\"config\")\n",
    "def main(cfg):\n",
    "    print_dict(cfg)\n",
    "    datamodule, simulator = simulate(cfg)\n",
    "    \n",
    "    if cfg.load:\n",
    "        network, trainer, tbl, datamodule = load(cfg, simulator)\n",
    "    else:\n",
    "        network, trainer, tbl = analyse(cfg, datamodule)\n",
    "    interpret(cfg, simulator, network, trainer, datamodule, tbl)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
