{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127e47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import omegaconf\n",
    "import hydra\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import swyft.lightning as sl\n",
    "import torch\n",
    "from lensx.logging_utils import log_post_plots, log_target_plots, log_train_plots\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from lensx.nn.subN.utils import print_dict\n",
    "\n",
    "# plt.switch_backend(\"agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e318a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(\"config_uniform.yaml\")\n",
    "from lensx.nn.subN.plot import plt_imshow\n",
    "imkwargs = dict(extent=(-2.5, 2.5, -2.5, 2.5), origin='lower') #left, right, bottom, top\n",
    "from tqdm.notebook import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0d9002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mock generated!\n"
     ]
    }
   ],
   "source": [
    "def check_obs(cfg):\n",
    "    try:   torch.load(cfg.inference.obs_path)\n",
    "    except FileNotFoundError: print('No mock generated!')\n",
    "        \n",
    "check_obs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b047e997",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eliasd/.pyenv/versions/3.9.7/envs/lens-3.9.7/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "def simulate(cfg):\n",
    "    # Loading simulator (potentially bounded)\n",
    "    simulator = hydra.utils.instantiate(cfg.simulation.model)\n",
    "\n",
    "    # Generate or load training data & generate datamodule\n",
    "    train_samples = sl.file_cache(\n",
    "        lambda: simulator.sample(cfg.simulation.store.store_size),\n",
    "        cfg.simulation.store.path,\n",
    "    )[: cfg.simulation.store.train_size]\n",
    "    datamodule = sl.SwyftDataModule(\n",
    "        store=train_samples,\n",
    "        model=simulator,  # Adds noise on the fly. `None` uses noise in store.\n",
    "        batch_size=cfg.estimation.batch_size,\n",
    "        num_workers=cfg.estimation.num_workers,\n",
    "    )\n",
    "\n",
    "    return datamodule, simulator\n",
    "datamodule, simulator = simulate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da78c343",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Setting up tensorboard logger, which defines also logdir (contains trained network)\n",
    "# tbl = pl_loggers.TensorBoardLogger(\n",
    "#     save_dir=cfg.tensorboard.save_dir,\n",
    "#     name=cfg.tensorboard.name,\n",
    "#     version=cfg.tensorboard.version,\n",
    "#     default_hp_metric=False,\n",
    "# )\n",
    "# logdir = (\n",
    "#     tbl.experiment.get_logdir()\n",
    "# )  # Directory where all logging information and checkpoints etc are stored\n",
    "\n",
    "# # Load network and train (or re-load trained network)\n",
    "# network = hydra.utils.instantiate(cfg.estimation.network, cfg)\n",
    "# #     network = ImgSegmNetwork(cfg, 1)\n",
    "\n",
    "# lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "# early_stop_callback = EarlyStopping(\n",
    "#     monitor=\"val_loss\",\n",
    "#     min_delta=cfg.estimation.early_stopping.min_delta,\n",
    "#     patience=cfg.estimation.early_stopping.patience,\n",
    "#     verbose=False,\n",
    "#     mode=\"min\",\n",
    "# )\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     monitor=\"val_loss\",\n",
    "#     dirpath=logdir + \"/checkpoint/\",\n",
    "#     filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "#     save_top_k=3,\n",
    "#     mode=\"min\",\n",
    "# )\n",
    "# trainer = sl.SwyftTrainer(\n",
    "#     accelerator=cfg.estimation.accelerator,\n",
    "#     gpus=1,\n",
    "#     max_epochs=cfg.estimation.max_epochs,\n",
    "#     logger=tbl,\n",
    "#     callbacks=[lr_monitor, early_stop_callback, checkpoint_callback],\n",
    "# )\n",
    "# best_checkpoint = logdir + \"/checkpoint/best.ckpt\"\n",
    "# if not os.path.isfile(best_checkpoint):\n",
    "#     trainer.fit(network, datamodule)\n",
    "#     shutil.copy(checkpoint_callback.best_model_path, best_checkpoint)\n",
    "#     trainer.test(network, datamodule)\n",
    "# else:\n",
    "#     print('realoding network?')\n",
    "#     trainer.fit(network, datamodule, ckpt_path=best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba925c41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained network\n",
      "best checkpoint is best.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "def load(cfg, simulator):\n",
    "    print('Loading trained network')\n",
    "    tbl = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=cfg.tensorboard.save_dir,\n",
    "        name=cfg.tensorboard.name,\n",
    "        version=cfg.tensorboard.version,\n",
    "        default_hp_metric=False,\n",
    "    )\n",
    "    logdir = (\n",
    "        tbl.experiment.get_logdir()\n",
    "    )  # Directory where all logging information and checkpoints etc are stored\n",
    "    \n",
    "#     epoch=09-val_loss=106464.16.ckpt\n",
    "\n",
    "    checkpoints = os.listdir( os.path.join(logdir, 'checkpoint') )\n",
    "    if 'best.ckpt' in checkpoints:\n",
    "        best_ckpt = 'best.ckpt'\n",
    "    else:\n",
    "        best_idx = np.argmax(list(map(int, [checkpoint[6:8] for checkpoint in checkpoints])))\n",
    "        best_ckpt = checkpoints[best_idx]\n",
    "    print(f'best checkpoint is {best_ckpt}')\n",
    "    \n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(logdir, f'checkpoint/{best_ckpt}'), map_location='cpu'\n",
    "    )\n",
    "\n",
    "    network = hydra.utils.instantiate(cfg.estimation.network, cfg)\n",
    "    network.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    train_samples = torch.load(cfg.simulation.store.path)\n",
    "    \n",
    "    trainer = sl.SwyftTrainer(accelerator=cfg.estimation.accelerator, gpus=1)\n",
    "    trainer.setup(None)\n",
    "    \n",
    "    datamodule = sl.SwyftDataModule(store=train_samples, model=simulator)\n",
    "    datamodule.setup()\n",
    "    \n",
    "    trainer.model = network\n",
    "    \n",
    "    return network, trainer, tbl, datamodule\n",
    "\n",
    "def analyse(cfg, datamodule):\n",
    "    # Setting up tensorboard logger, which defines also logdir (contains trained network)\n",
    "    tbl = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=cfg.tensorboard.save_dir,\n",
    "        name=cfg.tensorboard.name,\n",
    "        version=cfg.tensorboard.version,\n",
    "        default_hp_metric=False,\n",
    "    )\n",
    "    logdir = (\n",
    "        tbl.experiment.get_logdir()\n",
    "    )  # Directory where all logging information and checkpoints etc are stored\n",
    "\n",
    "    # Load network and train (or re-load trained network)\n",
    "    network = hydra.utils.instantiate(cfg.estimation.network, cfg)\n",
    "#     network = ImgSegmNetwork(cfg, 1)\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=cfg.estimation.early_stopping.min_delta,\n",
    "        patience=cfg.estimation.early_stopping.patience,\n",
    "        verbose=False,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=logdir + \"/checkpoint/\",\n",
    "        filename=\"{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    trainer = sl.SwyftTrainer(\n",
    "        accelerator=cfg.estimation.accelerator,\n",
    "        gpus=1,\n",
    "        max_epochs=cfg.estimation.max_epochs,\n",
    "        logger=tbl,\n",
    "        callbacks=[lr_monitor, early_stop_callback, checkpoint_callback],\n",
    "    )\n",
    "    best_checkpoint = logdir + \"/checkpoint/best.ckpt\"\n",
    "    if not os.path.isfile(best_checkpoint):\n",
    "        trainer.fit(network, datamodule)\n",
    "        shutil.copy(checkpoint_callback.best_model_path, best_checkpoint)\n",
    "        trainer.test(network, datamodule)\n",
    "    else:\n",
    "        print('realoding network?')\n",
    "        trainer.fit(network, datamodule, ckpt_path=best_checkpoint)\n",
    "\n",
    "    return network, trainer, tbl\n",
    "\n",
    "# network, trainer, tbl = analyse(cfg, datamodule)\n",
    "network, trainer, tbl, datamodule = load(cfg, simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21284b1",
   "metadata": {},
   "source": [
    "# Interpret again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e42d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import torch\n",
    "import swyft.lightning as sl\n",
    "\n",
    "from lensx.nn.subN.interpret import IsotonicRegressionCalibration\n",
    "from lensx.nn.subN.logging_utils_subN import LogIRC, LogPost, LogObs, LogBounds, LogSingleSub\n",
    "from lensx.nn.subN.inference import Infer, Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7079d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior,    M_frac    in subhalo log10 mass range\n",
      "3.25e-05, 8.33e-02:    [8.000 - 8.250]\n",
      "3.25e-05, 8.33e-02:    [8.250 - 8.500]\n",
      "3.25e-05, 8.33e-02:    [8.500 - 8.750]\n",
      "3.25e-05, 8.33e-02:    [8.750 - 9.000]\n",
      "3.25e-05, 8.33e-02:    [9.000 - 9.250]\n",
      "3.25e-05, 8.33e-02:    [9.250 - 9.500]\n",
      "3.25e-05, 8.33e-02:    [9.500 - 9.750]\n",
      "3.25e-05, 8.33e-02:    [9.750 - 10.000]\n",
      "3.25e-05, 8.33e-02:    [10.000 - 10.250]\n",
      "3.25e-05, 8.33e-02:    [10.250 - 10.500]\n",
      "3.25e-05, 8.33e-02:    [10.500 - 10.750]\n",
      "3.25e-05, 8.33e-02:    [10.750 - 11.000]\n"
     ]
    }
   ],
   "source": [
    "logdir = tbl.experiment.get_logdir()\n",
    "\n",
    "# Calculate expected n_sub\n",
    "Ms = datamodule.predict_dataloader().dataset[:]['z_sub'][:,:,0]\n",
    "n_sub_expect = torch.mean( torch.sum(Ms == 0, dim = 1).type(torch.float) )\n",
    "\n",
    "# Loading the inference class and \n",
    "infer = Infer(simulator, network, datamodule, n_sub_expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288b3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior information necessary for loggers\n",
    "prior, prior_grid = infer.calc_prior()[0], infer.prior_grid()\n",
    "grid_coords = infer.get_grid_coords()\n",
    "grid_low, grid_high = infer.grid_low, infer.grid_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39438cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simulations inference\n",
    "# posts_uncalib, targets = infer.get_posts(datamodule.predict_dataloader(), cfg.inference.n_infer)\n",
    "# torch.save(posts_uncalib, os.path.join(logdir, 'posts_uncalib.pt'))\n",
    "# torch.save(targets, os.path.join(logdir, 'targets.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd542d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calibration\n",
    "# irc = IsotonicRegressionCalibration(posts_uncalib, targets)    \n",
    "# posts_calib = irc.calibrate(posts_uncalib)\n",
    "# torch.save(posts_calib, os.path.join(logdir, 'posts_calib.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b725b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating reliability curve: 100%|██████████| 626/626 [00:02<00:00, 250.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved posterior and targets\n",
    "posts_uncalib = torch.load(os.path.join(logdir, 'posts_uncalib.pt'))\n",
    "targets       = torch.load(os.path.join(logdir, 'targets.pt'))\n",
    "posts_calib = torch.load(os.path.join(logdir, 'posts_calib.pt'))\n",
    "\n",
    "irc = IsotonicRegressionCalibration(posts_uncalib, targets)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5ac33fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10016"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts_uncalib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59689758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating reliability curve: 100%|██████████| 201/201 [00:02<00:00, 82.19it/s]\n",
      "Calculating reliability curve: 100%|██████████| 201/201 [00:02<00:00, 82.35it/s]\n",
      "Calculating reliability curve: 100%|██████████| 626/626 [00:02<00:00, 251.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Log simulation inference\n",
    "LogPost(tbl, posts_uncalib, targets, fig_kwargs = dict(dpi = 100, figsize = (4,3))).plot_all()\n",
    "LogPost(tbl, posts_calib,   targets, fig_kwargs = dict(dpi = 100, figsize = (4,3)), calib = 'calibrated').plot_all()\n",
    "LogIRC(tbl, irc).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b1fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir: ./lightning_logs3/uniform_noise0.25_sub0-5_m8.0-11.0_pix80_msc12_sim200000/version_0\n"
     ]
    }
   ],
   "source": [
    "tbl.experiment.flush()\n",
    "print(\"logdir:\", logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da793a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/scratch/ipykernel_21302/3017664728.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae8fa8",
   "metadata": {},
   "source": [
    "# Lavalamp plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784561b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10000):\n",
    "    test_sim = simulator.sample(1)\n",
    "    if (test_sim['z_sub'][0,:,0] > 10.).sum() > 3:\n",
    "        break\n",
    "test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad88f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_post_uncalib = infer.get_post(test_sim).squeeze(0)\n",
    "test_sim = infer.squeeze_obs(test_sim)\n",
    "test_post = irc.calibrate(test_post_uncalib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "\n",
    "for zlog in [False, True]:\n",
    "    logobs.plot_msc(zlog = zlog, \n",
    "                    plot_true = True,\n",
    "                    title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                    vminmax = True,\n",
    "                   );\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bffea9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "def get_alphas(post, a = 10, b = 1):\n",
    "    post = ( post - post.min() ) / post.max()\n",
    "    alphas = post * 0.8# 1 + b * np.exp( + a* post)\n",
    "#     alphas = ( alphas - alphas.min() ) / alphas.max()\n",
    "    return alphas\n",
    "\n",
    "# fig = plt.figure()\n",
    "# x = np.linspace(0, 1e-4)\n",
    "# y = get_alphas(x, a = a)\n",
    "# plt.plot(x, y, label = a)\n",
    "# plt.legend()    \n",
    "# plt.show()\n",
    "\n",
    "def normalize(d):\n",
    "    d -= d.min()\n",
    "    d /= d.max()\n",
    "    return d\n",
    "\n",
    "def cuboid_data(l, h):\n",
    "\n",
    "    x = [\n",
    "        [l[0], h[0], h[0], l[0], l[0]],  # x coordinate of points in bottom surface\n",
    "        [l[0], h[0], h[0], l[0], l[0]],  # x coordinate of points in upper surface\n",
    "        [l[0], h[0], h[0], l[0], l[0]],  # x coordinate of points in outside surface\n",
    "        [l[0], h[0], h[0], l[0], l[0]]  # x coordinate of points in inside surface\n",
    "        ] \n",
    "    y = [\n",
    "        [l[1], l[1], h[1], h[1], l[1]],  # y coordinate of points in bottom surface\n",
    "        [l[1], l[1], h[1], h[1], l[1]],  # y coordinate of points in upper surface\n",
    "        [l[1], l[1], l[1], l[1], l[1]],          # y coordinate of points in outside surface\n",
    "         [h[1], h[1], h[1], h[1], h[1]] # y coordinate of points in inside surface\n",
    "        ]    \n",
    "    z = [\n",
    "        [l[2], l[2], l[2], l[2], l[2]],                        # z coordinate of points in bottom surface\n",
    "         [h[2], h[2], h[2], h[2], h[2]],    # z coordinate of points in upper surface\n",
    "         [l[2], l[2], h[2], h[2], l[2]],                # z coordinate of points in outside surface\n",
    "         [l[2], l[2], h[2], h[2], l[2]],                 # z coordinate of points in inside surface\n",
    "        ]                \n",
    "    return np.array((x, y, z))\n",
    "\n",
    "def plotCubeAt(low=(0,0,0), high=(1,1,1), c=\"b\", alpha=1, ax=None):\n",
    "    # Plotting N cube elements at position pos\n",
    "    if ax != None:\n",
    "        X, Y, Z = cuboid_data(low, high)\n",
    "        ax.plot_surface(X, Y, Z, color=c, alpha=alpha)\n",
    "\n",
    "# def plotMatrix(ax, x, y, z, data, cmap=plt.cm.viridis, cax=None, alpha=1):\n",
    "#     # plot a Matrix \n",
    "#     norm = matplotlib.colors.Normalize(vmin=data.min(), vmax=data.max())\n",
    "#     colors = lambda i,j,k : matplotlib.cm.ScalarMappable(norm=norm,cmap = cmap).to_rgba(data[i,j,k]) \n",
    "#     alphas = lambda i,j,k : normalize(data)[i,j,k] \n",
    "#     for k, zi, in enumerate(tqdm(x)):\n",
    "#         for j, yi in enumerate(y):\n",
    "#             for i, xi in enumerate(z):\n",
    "# #                 print(i, j, k, data.shape)\n",
    "#                 if data[i,j,k] > 1e-3:\n",
    "#                     plotCubeAt(low=full_grid_low[i,j,k], high=full_grid_high[i,j,k],\n",
    "#                                c=colors(i,j,k), alpha=alphas(i,j,k),  ax=ax)\n",
    "            \n",
    "def plotMatrix(ax, x, y, z, data, threshold = 0., cmap=plt.cm.viridis, cax=None, alpha=1):\n",
    "    # plot a Matrix \n",
    "    norm = matplotlib.colors.Normalize(vmin=data.min(), vmax=data.max())\n",
    "    colors = lambda i,j,k : matplotlib.cm.ScalarMappable(norm=norm,cmap = cmap).to_rgba(data[i,j,k]) \n",
    "    alphas = lambda i,j,k : get_alphas(data)[i,j,k] \n",
    "    \n",
    "    for i, (x_low,x_high), in tqdm(enumerate(zip(x[:-1], x[1:])), total = len(x[1:])):\n",
    "        for j, (y_low,y_high) in enumerate(zip(y[:-1], y[1:])):\n",
    "            for k, (M_low,M_high) in enumerate(zip(z[:-1], z[1:])):\n",
    "                if data[i,j,k] > threshold:\n",
    "                    plotCubeAt(low=(x_low,y_low,M_low), high=(x_high,y_high,M_high),\n",
    "                               c=colors(i,j,k), \n",
    "                               alpha= alphas(i,j,k),  \n",
    "                               ax=ax)\n",
    "                    \n",
    "def plotMatrix2(ax, x, y, z, data, cmap=plt.cm.viridis, cax=None, alpha=1):\n",
    "    # plot a Matrix \n",
    "    norm = matplotlib.colors.Normalize(vmin=data.min(), vmax=data.max())\n",
    "    colors = lambda i,j: matplotlib.cm.ScalarMappable(norm=norm,cmap = cmap).to_rgba(data[i,j]) \n",
    "    \n",
    "    for i, (x_low,x_high), in tqdm(enumerate(zip(x[:-1], x[1:])), total = len(x[1:])):\n",
    "        for j, (y_low,y_high) in enumerate(zip(y[:-1], y[1:])):\n",
    "                plotCubeAt(low=(x_low,y_low,z-0.01), high=(x_high,y_high,z),\n",
    "                           c=colors(i,j), \n",
    "                           ax=ax)\n",
    "                    \n",
    "def plotLava(post, obs, threshold, azim = 0):\n",
    "\n",
    "\n",
    "\n",
    "#     post, obs, threshold, azim = test_post.cpu().numpy(), test_sim, 0.01*prior.min(), 270\n",
    "\n",
    "    m_centers, m_edges, xy_centers, xy_edges = grid_coords\n",
    "\n",
    "\n",
    "    z_sub = obs['z_sub'].numpy()\n",
    "    z_sub = z_sub[np.sum(np.abs(z_sub), axis = 1) != 0] \n",
    "    M_sub, x_sub, y_sub = z_sub.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(18,15))\n",
    "\n",
    "    labelsize = 15\n",
    "\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.view_init(elev=30., azim=azim)\n",
    "\n",
    "\n",
    "    plotMatrix(ax, xy_edges, xy_edges, m_edges, np.transpose(post, [2,1,0]), threshold = threshold)\n",
    "    ax.scatter(x_sub, y_sub, M_sub, s = 200, c = 'red', marker = 'x')\n",
    "\n",
    "    ax.set_xlim(xy_edges.min(), xy_edges.max())\n",
    "    ax.set_ylim(xy_edges.min(), xy_edges.max())\n",
    "    ax.set_zlim(m_edges.min(),  m_edges.max())\n",
    "\n",
    "    ax.set_xlabel(r\"$x\\ ['']$\", fontsize = labelsize)\n",
    "    ax.set_ylabel(r\"$y\\ ['']$\", fontsize = labelsize)\n",
    "    ax.set_zlabel(r'$log_{10}(M_{sub}/M_{\\odot})$', fontsize = labelsize)\n",
    "\n",
    "\n",
    "    X, Y = np.meshgrid(xy_edges, xy_edges)\n",
    "\n",
    "    # plotMatrix2(ax, xy_edges, xy_edges, m_edges.min(), obs['img'])\n",
    "\n",
    "\n",
    "\n",
    "    # norm = matplotlib.colors.Normalize()\n",
    "    # ax.set_axisbelow(False)\n",
    "\n",
    "    # ax.imshow(obs['img'], **imkwargs)\n",
    "\n",
    "    # ax.plot_surface(X, Y, np.atleast_2d(m_edges.min()), facecolors = plt.cm.viridis(norm(obs['img'])), \n",
    "    #                 rcount = 80,\n",
    "    #                 ccount = 80,\n",
    "    #                 linewidth=0,\n",
    "    #                 antialiased=True,\n",
    "    #                 alpha = 0.5, shade = False, zorder = -100)#, 1, zdir = 'z', offset = 0, cmap = 'viridis')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plotLava(test_post.cpu().numpy(), test_sim, \n",
    "         threshold = prior.min() ,\n",
    "         azim = 270\n",
    "        )\n",
    "\n",
    "# plotLava(test_post.cpu().numpy(), test_sim, \n",
    "#          threshold = prior.min() ,\n",
    "#          azim = 45\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "post, obs = test_post.cpu().numpy(), test_sim\n",
    "m_centers, m_edges, xy_centers, xy_edges = grid_coords\n",
    "X, Y, Z = torch.meshgrid(xy_centers, xy_centers, m_centers)\n",
    "values = np.transpose(post, [2, 1, 0])\n",
    "\n",
    "z_sub = obs['z_sub'].numpy()\n",
    "z_sub = z_sub[np.sum(np.abs(z_sub), axis = 1) != 0] \n",
    "M_sub, x_sub, y_sub = z_sub.T\n",
    "\n",
    "# values = np.log10(values)\n",
    "\n",
    "\n",
    "# x1 = np.linspace(2, 4, 3) \n",
    "# y1 = np.linspace(2, 5, 4) \n",
    "# z1 = np.linspace(2, 5, 2) \n",
    "# X, Y, Z = np.meshgrid(x1, y1, z1)\n",
    "# values = (np.sin(X**2 + Y**2))/(X**2 + Y**2)\n",
    "\n",
    "# i, j, k = 6, 6, 2\n",
    "# X = X[i,j,k]\n",
    "# Y = Y[i,j,k]\n",
    "# Z = Z[i,j,k]\n",
    "# values = values[i,j,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9873728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeced206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = cuboid_data([0.1, 0.1, 0.1], [0.5, 0.5, 0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338192f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mesh(fig, low, high, opacity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9dd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b42b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = matplotlib.colors.Normalize()\n",
    "im = np.array(obs['img'])\n",
    "colorscale = [colormap(i) for i in np.linspace(0, 1, 10)]\n",
    "\n",
    "im_x, im_y = im.shape\n",
    "x = np.linspace(-2.5,2.5, im_x)\n",
    "y = np.linspace(-2.5,2.5, im_y)\n",
    "z = np.ones(im.shape[:2]) * grid_low[0]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1,\n",
    "                    specs=[[{'is_3d': True}]],#, {'is_3d': True}]],\n",
    "#                     subplot_titles=['Normal scale', 'Logarithmic scale'],\n",
    "                    )\n",
    "\n",
    "def cuboid_data(l, h):\n",
    "    x = [l[0], l[0], h[0], h[0], l[0], l[0], h[0], h[0]]\n",
    "    y = [l[1], h[1], h[1], l[1], l[1], h[1], h[1], l[1]]\n",
    "    z = [l[2], l[2], l[2], l[2], h[2], h[2], h[2], h[2]]\n",
    "    return np.array((x, y, z))\n",
    "\n",
    "x, y, z = cuboid_data([0.1, 0.1, 0.1], [0.5, 0.5, 0.5])\n",
    "fig.add_trace(go.Mesh3d(\n",
    "    x = x, y = y, z = z,\n",
    "    i = [7, 0, 0, 0, 4, 4, 6, 6, 4, 0, 3, 2],\n",
    "    j = [3, 4, 1, 2, 5, 6, 5, 2, 0, 1, 6, 3],\n",
    "    k = [0, 7, 2, 3, 6, 7, 1, 1, 5, 5, 7, 6],\n",
    "    opacity = 0.4,\n",
    "    flatshading = True\n",
    "\n",
    "))\n",
    "\n",
    "fig.show()\n",
    "# fig.write_html(\"plotly.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a53d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "x == [0.608, 0.608, 0.998, 0.998, 0.608, 0.608, 0.998, 0.998]\n",
    "y == [0.091, 0.963, 0.963, 0.091, 0.091, 0.963, 0.963, 0.091]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuboid_data(l, h):\n",
    "    x = [l[0], l[0], h[0], h[0], l[0], l[0], h[0], h[0]]\n",
    "    y = [l[1], h[1], h[1], l[1], l[1], h[1], h[1], l[1]]\n",
    "    z = [l[2], l[2], l[2], l[2], h[2], h[2], h[2], h[2]]\n",
    "    return np.array((x, y, z))\n",
    "\n",
    "x, y, z = cuboid_data([.608, .091, .140], [.998, .963, .571])\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "     go.Mesh3d(\n",
    "         x = x, y = y, z = z,\n",
    "        # 8 vertices of a cube\n",
    "#         x=[0.608, 0.608, 0.998, 0.998, 0.608, 0.608, 0.998, 0.998],\n",
    "#         y=[0.091, 0.963, 0.963, 0.091, 0.091, 0.963, 0.963, 0.091],\n",
    "#         z=[0.140, 0.140, 0.140, 0.140, 0.571, 0.571, 0.571, 0.571],\n",
    "\n",
    "        i = [7, 0, 0, 0, 4, 4, 6, 6, 4, 0, 3, 2],\n",
    "        j = [3, 4, 1, 2, 5, 6, 5, 2, 0, 1, 6, 3],\n",
    "        k = [0, 7, 2, 3, 6, 7, 1, 1, 5, 5, 7, 6],\n",
    "        opacity=0.6,\n",
    "        color='#DC143C',\n",
    "        flatshading = True\n",
    "    )                    \n",
    "    ])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e31ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colormap(x):\n",
    "    cmap = matplotlib.cm.get_cmap('viridis')(x)\n",
    "    return [x, f'rgb{cmap[:-1]}']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = matplotlib.colors.Normalize()\n",
    "im = np.array(obs['img'])\n",
    "colorscale = [colormap(i) for i in np.linspace(0, 1, 10)]\n",
    "\n",
    "im_x, im_y = im.shape\n",
    "x = np.linspace(-2.5,2.5, im_x)\n",
    "y = np.linspace(-2.5,2.5, im_y)\n",
    "z = np.ones(im.shape[:2]) * grid_low[0]\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2,\n",
    "                    specs=[[{'is_3d': True}, {'is_3d': True}]],\n",
    "                    subplot_titles=['Normal scale', 'Logarithmic scale'],\n",
    "                    )\n",
    "\n",
    "for ncol, v, cbar_x in zip([1, 2], [values, np.log10(values)], [-0.10, None]):\n",
    "    fig.add_trace(go.Volume(\n",
    "        x=X.flatten(),\n",
    "        y=Y.flatten(),\n",
    "        z=Z.flatten(),\n",
    "        value=v.flatten(),\n",
    "        surface_count = 20,\n",
    "    #     opacity = 0.1,\n",
    "        opacityscale = [[0, 0], [1, 0.9]],\n",
    "        colorbar_x=cbar_x,\n",
    "    ), 1, ncol)\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x = x_sub,\n",
    "        y = y_sub,\n",
    "        z = M_sub,\n",
    "        mode ='markers',\n",
    "        marker = dict(\n",
    "            color = 'red',\n",
    "            symbol = 'x',\n",
    "            size = 5,\n",
    "        ),\n",
    "    ), 1, ncol)\n",
    "\n",
    "fig.add_trace(go.Surface(x=x, y=y, z=z,\n",
    "    surfacecolor=im, \n",
    "    colorscale=colorscale,\n",
    "    showscale=False,\n",
    "#     lighting_diffuse=1,\n",
    "#     lighting_ambient=1,\n",
    "#     lighting_fresnel=1,\n",
    "#     lighting_roughness=1,\n",
    "#     lighting_specular=0.5,\n",
    "\n",
    "), 1, 1)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height = 800, \n",
    "    width = 1600, \n",
    "    title_text=\"Subhalo posteriors test\",\n",
    "    scene = dict(\n",
    "        xaxis=dict(title=r\"x\"),\n",
    "        yaxis=dict(title=r\"y\"),\n",
    "        zaxis=dict(title=r'M'),\n",
    "    ),\n",
    "    showlegend=False\n",
    ")\n",
    "# fig.show()\n",
    "fig.write_html(\"plotly.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb883c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import plotly.graph_objects as go\n",
    "from scipy import misc\n",
    "\n",
    "# im = misc.face()\n",
    "# im_x, im_y, im_layers = im.shape\n",
    "# eight_bit_img = Image.fromarray(im).convert('P', palette='WEB', dither=None)\n",
    "# dum_img = Image.fromarray(np.ones((3,3,3), dtype='uint8')).convert('P', palette='WEB')\n",
    "# idx_to_color = np.array(dum_img.getpalette()).reshape((-1, 3))\n",
    "# colorscale=[[i/255.0, \"rgb({}, {}, {})\".format(*rgb)] for i, rgb in enumerate(idx_to_color)]\n",
    "\n",
    "# Sample data: 3 trajectories\n",
    "t = np.linspace(0, 10, 200)\n",
    "df = pd.concat([pd.DataFrame({'x': 400 * (1 + np.cos(t + 5 * i)), 'y': 400 * (1 + np.sin(t)), 't': t, 'id': f'id000{i}'}) for i in [0, 1, 2]])\n",
    "# im = im.swapaxes(0, 1)[:, ::-1]\n",
    "colors=df['t'].to_list()\n",
    "\n",
    "# # 3d scatter plot\n",
    "x = np.linspace(0,404.8, im_x)\n",
    "y = np.linspace(0, 504.4, im_y)\n",
    "z = np.zeros(im.shape[:2])\n",
    "\n",
    "# x = np.linspace(-2.5,2.5, im_x)\n",
    "# y = np.linspace(-2.5,2.5, im_y)\n",
    "# z = np.ones(im.shape) * 8.\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=df['x'], \n",
    "    y=df['y'], \n",
    "    z=df['t'],\n",
    "    marker=dict(\n",
    "        color=colors,\n",
    "        size=4,\n",
    "    )\n",
    "    ))\n",
    "\n",
    "fig.add_trace(go.Surface(x=x, y=y, z=z,\n",
    "    surfacecolor=eight_bit_img, \n",
    "    cmin=0, \n",
    "    cmax=255,\n",
    "    colorscale=colorscale,\n",
    "    showscale=False,\n",
    "    lighting_diffuse=1,\n",
    "    lighting_ambient=1,\n",
    "    lighting_fresnel=1,\n",
    "    lighting_roughness=1,\n",
    "    lighting_specular=0.5,\n",
    "\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"My 3D scatter plot\",\n",
    "    width=800,\n",
    "    height=800,\n",
    "    scene=dict(xaxis_visible=True,\n",
    "                yaxis_visible=True, \n",
    "                zaxis_visible=True, \n",
    "                xaxis_title=\"X\",\n",
    "                yaxis_title=\"Y\",\n",
    "                zaxis_title=\"Z\" ,\n",
    "\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b36730",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(vol.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(vol.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57daa709",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Generate nicely looking random 3D-field\n",
    "np.random.seed(0)\n",
    "l = 30\n",
    "X, Y, Z = np.mgrid[:l, :l, :l]\n",
    "vol = np.zeros((l, l, l))\n",
    "pts = (l * np.random.rand(3, 15)).astype(np.int)\n",
    "vol[tuple(indices for indices in pts)] = 1\n",
    "from scipy import ndimage\n",
    "vol = ndimage.gaussian_filter(vol, 4)\n",
    "vol /= vol.max()\n",
    "\n",
    "fig = go.Figure(data=go.Volume(\n",
    "    x=X.flatten(), y=Y.flatten(), z=Z.flatten(),\n",
    "    value=vol.flatten(),\n",
    "    isomin=0.2,\n",
    "    isomax=0.7,\n",
    "    opacity=0.1,\n",
    "    surface_count=100,\n",
    "    ))\n",
    "fig.update_layout(scene_xaxis_showticklabels=False,\n",
    "                  scene_yaxis_showticklabels=False,\n",
    "                  scene_zaxis_showticklabels=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b404a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "     go.Scatter3d(x=x, y=y, z=z,\n",
    "                  mode='markers',\n",
    "                  marker=dict(size=2)\n",
    "                 ),\n",
    "     go.Mesh3d(\n",
    "        # 8 vertices of a cube\n",
    "        x=[0.608, 0.608, 0.998, 0.998, 0.608, 0.608, 0.998, 0.998],\n",
    "        y=[0.091, 0.963, 0.963, 0.091, 0.091, 0.963, 0.963, 0.091],\n",
    "        z=[0.140, 0.140, 0.140, 0.140, 0.571, 0.571, 0.571, 0.571],\n",
    "\n",
    "        i = [7, 0, 0, 0, 4, 4, 6, 6, 4, 0, 3, 2],\n",
    "        j = [3, 4, 1, 2, 5, 6, 5, 2, 0, 1, 6, 3],\n",
    "        k = [0, 7, 2, 3, 6, 7, 1, 1, 5, 5, 7, 6],\n",
    "        opacity=0.6,\n",
    "        color='#DC143C',\n",
    "        flatshading = True\n",
    "    )                    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c72dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Scatter3d(\n",
    "    x = df['XXXX'],\n",
    "    y = df['XXXX'],\n",
    "    z = df['XXXX'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=12,\n",
    "        color=z,                # set color to an array/list of desired values\n",
    "        colorscale='Viridis',   # choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace1]\n",
    "layout = go.Layout(\n",
    "    scene = dict(\n",
    "                    xaxis = dict(\n",
    "                        title='XXXX-XXXXXX'),\n",
    "                    yaxis = dict(\n",
    "                        title='XXXX-XXXXXX'),\n",
    "                    zaxis = dict(\n",
    "                        title='XXXX-XXXXXX'),),\n",
    "    margin=dict(\n",
    "        r=20, b=10, l=10, t=10\n",
    "    )\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "#py.iplot(fig, filename='3d-scatter-colorscale')\n",
    "plot(fig, filename='D:\\\\plots\\\\3dplots\\\\xx.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.plot_surface(X, Y, np.atleast_2d(m_edges.min()), facecolors = plt.cm.viridis(norm(obs['img'])), \n",
    "                alpha = 0.1, shade = False, zorder = -100)#, 1, zdir = 'z', offset = 0, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5489ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cm.viridis(norm(obs['img']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7f330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(obs['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in cmap(obs['img']).T:\n",
    "    plt.imshow(p)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6963b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd32fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_centers, m_edges, xy_centers, xy_edges = grid_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8d4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ecab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((1, 2, 3))\n",
    "np.transpose(x, (1, 0, 2)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "post.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(post, (1, 2, 0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs['z_sub'].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a1866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eade643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.swapaxes(obs['z_sub'].T.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(obs['z_sub'].numpy(), axes = [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d35560",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_grid_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7baa30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torch.stack(torch.meshgrid((m_edges, xy_edges, xy_edges)), dim = -1)\n",
    "full_grid_low  = grid[:-1,:-1,:-1]\n",
    "full_grid_high = grid[1:,1:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53c9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuboid_data([0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,15))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(elev=10., azim=10)\n",
    "plotMatrix(ax, x, y, z, data_value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f9ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         azims = [10., 100., 190., 250.]\n",
    "azims = [10.]\n",
    "\n",
    "fig = plt.figure(figsize=(18,15))\n",
    "\n",
    "for i, azim in enumerate(azims):\n",
    "    ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "#         plotMatrix(ax, x, y, z, data_value)\n",
    "\n",
    "#         ax.scatter(*scatter, marker = 'x', color = 'red', s = 100)\n",
    "\n",
    "    ax.view_init(elev=10., azim=azim)\n",
    "\n",
    "    labelsize = 15\n",
    "    ax.set_xlabel(r'$x\\ [\\deg]$', fontsize = labelsize)\n",
    "    ax.set_ylabel(r'$y\\ [\\deg]$', fontsize = labelsize)\n",
    "    ax.set_zlabel(r'$log_{10}(M_{sub}/M_{\\odot})$', fontsize = labelsize)\n",
    "\n",
    "    ax.set_xticks(np.linspace(0, L, 11)[1::2])\n",
    "    ax.set_xticklabels(np.linspace(-2.5, 2.5, 11)[1::2])\n",
    "    ax.set_yticks(np.linspace(0, L, 11)[1::2])\n",
    "    ax.set_yticklabels(np.linspace(-2.5, 2.5, 11)[1::2])\n",
    "    ax.set_zticks(z)\n",
    "    ax.set_zticklabels(np.log10(m_centers.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "ax_cb = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "\n",
    "norm = matplotlib.colors.Normalize(vmin=data_value.min(), vmax=data_value.max())\n",
    "cbar = matplotlib.colorbar.ColorbarBase(ax_cb, cmap=plt.cm.viridis,\n",
    "                                norm=norm,\n",
    "                                orientation='vertical')  \n",
    "#     return fig\n",
    "#     plt.savefig(f'figs/lava_{plot_name}.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#     print('Done!')\n",
    "    \n",
    "# plotLava(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39532e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    def get_alphas(post):\n",
    "        post = ( post - post.min() ) / post.max()\n",
    "\n",
    "        a, b = 50, 1\n",
    "        alphas = 1 - b * np.exp( - a * post)\n",
    "\n",
    "        return alphas\n",
    "\n",
    "    def normalize(d):\n",
    "        d -= d.min()\n",
    "        d /= d.max()\n",
    "        return d\n",
    "\n",
    "    def cuboid_data(center, size=(1,1,1)):\n",
    "        # code taken from\n",
    "        # http://stackoverflow.com/questions/30715083/python-plotting-a-wireframe-3d-cuboid?noredirect=1&lq=1\n",
    "        # suppose axis direction: x: to left; y: to inside; z: to upper\n",
    "        # get the (left, outside, bottom) point\n",
    "        o = [a - b / 2 for a, b in zip(center, size)]\n",
    "        # get the length, width, and height\n",
    "        l, w, h = size\n",
    "        x = [[o[0], o[0] + l, o[0] + l, o[0], o[0]],  # x coordinate of points in bottom surface\n",
    "             [o[0], o[0] + l, o[0] + l, o[0], o[0]],  # x coordinate of points in upper surface\n",
    "             [o[0], o[0] + l, o[0] + l, o[0], o[0]],  # x coordinate of points in outside surface\n",
    "             [o[0], o[0] + l, o[0] + l, o[0], o[0]]]  # x coordinate of points in inside surface\n",
    "        y = [[o[1], o[1], o[1] + w, o[1] + w, o[1]],  # y coordinate of points in bottom surface\n",
    "             [o[1], o[1], o[1] + w, o[1] + w, o[1]],  # y coordinate of points in upper surface\n",
    "             [o[1], o[1], o[1], o[1], o[1]],          # y coordinate of points in outside surface\n",
    "             [o[1] + w, o[1] + w, o[1] + w, o[1] + w, o[1] + w]]    # y coordinate of points in inside surface\n",
    "        z = [[o[2], o[2], o[2], o[2], o[2]],                        # z coordinate of points in bottom surface\n",
    "             [o[2] + h, o[2] + h, o[2] + h, o[2] + h, o[2] + h],    # z coordinate of points in upper surface\n",
    "             [o[2], o[2], o[2] + h, o[2] + h, o[2]],                # z coordinate of points in outside surface\n",
    "             [o[2], o[2], o[2] + h, o[2] + h, o[2]]]                # z coordinate of points in inside surface\n",
    "        return np.array((x, y, z))\n",
    "\n",
    "    def plotCubeAt(pos=(0,0,0), c=\"b\", alpha=1, ax=None):\n",
    "        # Plotting N cube elements at position pos\n",
    "        if ax !=None:\n",
    "            X, Y, Z = cuboid_data( (pos[0],pos[1],pos[2]) )\n",
    "            ax.plot_surface(X, Y, Z, color=c, rstride=1, cstride=1, alpha=alpha)\n",
    "\n",
    "    def plotMatrix(ax, x, y, z, data, cmap=plt.cm.viridis, cax=None, alpha=1):\n",
    "        # plot a Matrix \n",
    "        norm = matplotlib.colors.Normalize(vmin=data.min(), vmax=data.max())\n",
    "        colors = lambda i,j,k : matplotlib.cm.ScalarMappable(norm=norm,cmap = cmap).to_rgba(data[i,j,k]) \n",
    "        alphas = lambda i,j,k : normalize(data)[i,j,k] \n",
    "        for i, xi in enumerate(tqdm(x)):\n",
    "                for j, yi in enumerate(y):\n",
    "                    for k, zi, in enumerate(z):\n",
    "                        plotCubeAt(pos=(xi, yi, zi), c=colors(i,j,k), alpha=alphas(i,j,k),  ax=ax)\n",
    "\n",
    "\n",
    "    def plotLava(obs0_i = -1):\n",
    "        post, target_coords, scatter, obs0_i = get_pred(obs0_i = obs0_i)\n",
    "\n",
    "        # x and y and z coordinates\n",
    "        x = np.array(range(21)) #np.linspace(0,9,11) #\n",
    "        y = np.array(range(10,15))\n",
    "        z = np.array(range(15,20))\n",
    "        # data_value = np.random.randint(1,4, size=(len(x), len(y), len(z)) )\n",
    "        data_value = np.random.rand(len(x), len(y), len(z))\n",
    "\n",
    "        x = y = np.arange(L) #np.linspace(0, 1, L)\n",
    "        z = np.arange(len(m_centers)) #m_centers.numpy()\n",
    "        data_value = np.transpose(post, [1,2,0])\n",
    "\n",
    "        azims = [10., 100., 190., 250.]\n",
    "        # azims = [10.]\n",
    "\n",
    "        print(data_value.shape)\n",
    "        plot_name = f'{mre_name}_obs0_i={obs0_i}'\n",
    "        print(f'plot_name {plot_name}')\n",
    "\n",
    "        fig = plt.figure(figsize=(18,15))\n",
    "\n",
    "        for i, azim in enumerate(azims):\n",
    "            ax = fig.add_subplot(2, 2, i+1, projection='3d')\n",
    "            plotMatrix(ax, x, y, z, data_value)\n",
    "\n",
    "            ax.scatter(*scatter, marker = 'x', color = 'red', s = 100)\n",
    "\n",
    "            ax.view_init(elev=10., azim=azim)\n",
    "\n",
    "            labelsize = 15\n",
    "            ax.set_xlabel(r'$x\\ [\\deg]$', fontsize = labelsize)\n",
    "            ax.set_ylabel(r'$y\\ [\\deg]$', fontsize = labelsize)\n",
    "            ax.set_zlabel(r'$log_{10}(M_{sub}/M_{\\odot})$', fontsize = labelsize)\n",
    "\n",
    "            ax.set_xticks(np.linspace(0, L, 11)[1::2])\n",
    "            ax.set_xticklabels(np.linspace(-2.5, 2.5, 11)[1::2])\n",
    "            ax.set_yticks(np.linspace(0, L, 11)[1::2])\n",
    "            ax.set_yticklabels(np.linspace(-2.5, 2.5, 11)[1::2])\n",
    "            ax.set_zticks(z)\n",
    "            ax.set_zticklabels(np.log10(m_centers.numpy()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        fig.subplots_adjust(right=0.8)\n",
    "        ax_cb = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "\n",
    "        norm = matplotlib.colors.Normalize(vmin=data_value.min(), vmax=data_value.max())\n",
    "        cbar = matplotlib.colorbar.ColorbarBase(ax_cb, cmap=plt.cm.viridis,\n",
    "                                        norm=norm,\n",
    "                                        orientation='vertical')  \n",
    "\n",
    "        plt.savefig(f'figs/lava_{plot_name}.png',bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617ac99",
   "metadata": {},
   "source": [
    "# Extra Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5fe1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testdata(simulator, infer, irc, n_test = 4):\n",
    "    CALIBRATE = True\n",
    "    test_posts, test_sims = [], []\n",
    "\n",
    "    for _ in range(n_test):\n",
    "        test_sim = simulator.sample(1)\n",
    "\n",
    "        test_post_uncalib = infer.get_post(test_sim).squeeze(0)\n",
    "        test_sim = infer.squeeze_obs(test_sim)\n",
    "        test_post = irc.calibrate(test_post_uncalib) if CALIBRATE is True else test_post_uncalib\n",
    "\n",
    "        test_sims.append(test_sim)\n",
    "        test_posts.append(test_post)\n",
    "\n",
    "    test_posts = torch.stack(test_posts)       \n",
    "    \n",
    "    \n",
    "    return test_sims, test_posts\n",
    "test_sims, test_posts = get_testdata(simulator, infer, irc, n_test = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6c35e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_testdata(test_sims, test_posts, zlog = True, vminmax = True):\n",
    "    vmax, vmin = test_posts.max(), test_posts.min()\n",
    "    for test_sim, test_post in zip(test_sims, test_posts):\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax) if vminmax is True else {}\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "#                         **kwargs, \n",
    "                        vminmax = True,\n",
    "                       );\n",
    "#     for test_sim, test_post in zip(test_sims, test_posts):\n",
    "#         logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "#         logobs.plot_obs();\n",
    "        \n",
    "# plot_testdata(test_sims, test_posts, zlog = True)\n",
    "plot_testdata(test_sims, test_posts, zlog = False)#, vminmax = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce990d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "#     posts_uncalib = torch.load(os.path.join(tbl.experiment.get_logdir(), 'posts_uncalib.pt'))\n",
    "#     targets       = torch.load(os.path.join(tbl.experiment.get_logdir(), 'targets.pt'))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#     # Observation inference\n",
    "#     obs = torch.load(cfg.inference.obs_path)\n",
    "#     obs_post = infer.get_post( dict(img=obs['img'].unsqueeze(0).cpu()))\n",
    "    \n",
    "#     # Log observation inference\n",
    "#     log_obs = LogObs(tbl, obs, obs_post, prior, grid_coords, fig_kwargs = dict(dpi = 250, figsize = (8, 5)))\n",
    "#     log_obs.plot_all()   \n",
    "    \n",
    "\n",
    "\n",
    "#     if (cfg.simulation.model.n_sub, cfg.estimation.network.n_msc) == (1, 1):\n",
    "#         log_single_sub = LogSingleSub(tbl, obs, obs_post, prior_grid, grid_coords)\n",
    "#         log_single_sub.plot_all()\n",
    "\n",
    "    # Log bounds\n",
    "#     log_bounds = LogBounds(tbl, obs, obs_post, grid_coords, grid_low, grid_high)\n",
    "#     log_bounds.plot_all()\n",
    "                              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fefe689",
   "metadata": {},
   "source": [
    "# Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import torch\n",
    "import swyft.lightning as sl\n",
    "\n",
    "from lensx.nn.subN.interpret import IsotonicRegressionCalibration\n",
    "from lensx.nn.subN.logging_utils_subN import LogIRC, LogPost, LogObs, LogBounds, LogSingleSub\n",
    "from lensx.nn.subN.inference import Infer, Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff9bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logdir = tbl.experiment.get_logdir()\n",
    "\n",
    "# Calculate expected n_sub\n",
    "Ms = datamodule.predict_dataloader().dataset[:]['z_sub'][:,:,0]\n",
    "n_sub_expect = torch.mean( torch.sum(Ms == 0, dim = 1).type(torch.float) )\n",
    "\n",
    "# Loading the inference class and \n",
    "infer = Infer(simulator, network, datamodule, n_sub_expect)\n",
    "\n",
    "# Prior information necessary for loggers\n",
    "prior, prior_grid = infer.calc_prior(), infer.prior_grid()[0]\n",
    "grid_coords = infer.get_grid_coords()\n",
    "grid_low, grid_high = infer.grid_low, infer.grid_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_uncalib = torch.load(os.path.join(logdir, 'posts_uncalib.pt'))\n",
    "posts_calib = torch.load(os.path.join(logdir, 'posts_calib.pt'))\n",
    "targets       = torch.load(os.path.join(logdir, 'targets.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21149efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simulations inference\n",
    "# posts_uncalib, targets = infer.get_posts(datamodule.predict_dataloader(), cfg.inference.n_infer)\n",
    "# torch.save(posts_uncalib, os.path.join(logdir, 'posts_uncalib.pt'))\n",
    "# torch.save(targets, os.path.join(logdir, 'targets.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "irc = IsotonicRegressionCalibration(posts_uncalib, targets)    \n",
    "# posts_calib = irc.calibrate(posts_uncalib)\n",
    "# torch.save(posts_calib, os.path.join(logdir, 'posts_calib.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3102713",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogIRC(tbl, irc).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_testdata(simulator, infer, irc, n_test = 4):\n",
    "    CALIBRATE = True\n",
    "    test_posts, test_sims = [], []\n",
    "\n",
    "    for _ in range(n_test):\n",
    "        test_sim = simulator.sample(1)\n",
    "\n",
    "        test_post_uncalib = infer.get_post(test_sim).squeeze(0)\n",
    "        test_sim = infer.squeeze_obs(test_sim)\n",
    "        test_post = irc.calibrate(test_post_uncalib) if CALIBRATE is True else test_post_uncalib\n",
    "\n",
    "        test_sims.append(test_sim)\n",
    "        test_posts.append(test_post)\n",
    "\n",
    "    test_posts = torch.stack(test_posts)       \n",
    "    \n",
    "    \n",
    "    return test_sims, test_posts\n",
    "test_sims, test_posts = get_testdata(simulator, infer, irc, n_test = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027a041",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_testdata(test_sims, test_posts, zlog = True, vminmax = True):\n",
    "    vmax, vmin = test_posts.max(), test_posts.min()\n",
    "    for test_sim, test_post in zip(test_sims, test_posts):\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax) if vminmax is True else {}\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                        **kwargs, \n",
    "                       );\n",
    "    for test_sim, test_post in zip(test_sims, test_posts):\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        logobs.plot_obs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d151b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_testdata(test_sims, test_posts, zlog = True)\n",
    "# plot_testdata(test_sims, test_posts, zlog = False, vminmax = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f143aaf1",
   "metadata": {},
   "source": [
    "# Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1401df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import torch\n",
    "import swyft.lightning as sl\n",
    "\n",
    "from lensx.nn.subN.interpret import IsotonicRegressionCalibration\n",
    "from lensx.nn.subN.logging_utils_subN import LogIRC, LogPost, LogObs, LogBounds, LogSingleSub\n",
    "from lensx.nn.subN.inference import Infer, Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e529e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = datamodule.predict_dataloader().dataset[:]['z_sub'][:,:,0]\n",
    "n_sub_expect = torch.mean( torch.sum(Ms == 0, dim = 1).type(torch.float) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = tbl.experiment.get_logdir()\n",
    "\n",
    "# Loading the inference class and \n",
    "infer = Infer(simulator, network, datamodule, n_sub_expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior information necessary for loggers\n",
    "prior, prior_grid = infer.calc_prior(), infer.prior_grid()\n",
    "grid_coords = infer.get_grid_coords()\n",
    "grid_low, grid_high = infer.grid_low, infer.grid_high\n",
    "\n",
    "# Simulations inference\n",
    "posts_uncalib, targets = infer.get_posts(datamodule.predict_dataloader(), cfg.inference.n_infer)\n",
    "torch.save(posts_uncalib, os.path.join(logdir, 'posts_uncalib.pt'))\n",
    "torch.save(targets, os.path.join(logdir, 'targets.pt'))\n",
    "# posts_uncalib = torch.load(os.path.join(tbl.experiment.get_logdir(), 'posts.pt'))\n",
    "# targets       = torch.load(os.path.join(tbl.experiment.get_logdir(), 'targets.pt'))\n",
    "\n",
    "# Calibration\n",
    "irc = IsotonicRegressionCalibration(posts_uncalib, targets)    \n",
    "posts_calib = irc.calibrate(posts_uncalib)\n",
    "torch.save(posts_calib, os.path.join(logdir, 'posts_calib.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70004c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogIRC(None, irc).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0450d4",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce327f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def interpret(cfg, simulator, network, trainer, datamodule, tbl):\n",
    "    hydra.utils.call(\n",
    "        cfg.inference.interpreter, cfg, simulator, network, trainer, datamodule, tbl\n",
    "    )\n",
    "\n",
    "# def interpret(cfg, simulator, network, trainer, datamodule, tbl):\n",
    "#     hydra.utils.instantiate(cfg.inference.interpreter, cfg, simulator, network, trainer, datamodule, tbl)\n",
    "\n",
    "interpret(cfg, simulator, network, trainer, datamodule, tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import torch\n",
    "import swyft.lightning as sl\n",
    "\n",
    "from lensx.nn.subN.interpret import IsotonicRegressionCalibration\n",
    "from lensx.nn.subN.logging_utils_subN import LogIRC, LogPost, LogObs, LogBounds, LogSingleSub\n",
    "from lensx.nn.subN.inference import Infer, Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3033306",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = tbl.experiment.get_logdir()\n",
    "\n",
    "# Loading the inference class and \n",
    "infer = Infer(simulator, network, datamodule)\n",
    "\n",
    "# Prior information necessary for loggers\n",
    "prior, prior_grid = infer.calc_prior(), infer.prior_grid()\n",
    "grid_coords = infer.get_grid_coords()\n",
    "grid_low, grid_high = infer.grid_low, infer.grid_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulations inference\n",
    "#     posts_uncalib, targets = infer.get_posts(datamodule.predict_dataloader(), cfg.inference.n_infer)\n",
    "#     torch.save(posts_uncalib, os.path.join(logdir, 'posts_uncalib.pt'))\n",
    "#     torch.save(targets, os.path.join(logdir, 'targets.pt'))\n",
    "posts_uncalib = torch.load(os.path.join(tbl.experiment.get_logdir(), 'posts.pt'))\n",
    "targets       = torch.load(os.path.join(tbl.experiment.get_logdir(), 'targets.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(posts_uncalib, mult = 1):\n",
    "    ndim = posts_uncalib.ndim\n",
    "    if ndim == 3: posts_uncalib = posts_uncalib.unsqueeze(0) \n",
    "    sum_posts_uncalib = torch.sum(posts_uncalib, dim = (1,2,3))\n",
    "    sum_posts_uncalib = sum_posts_uncalib.unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "    sum_posts_uncalib = torch.tile(sum_posts_uncalib, (1, *posts_uncalib.shape[1:]))\n",
    "    posts_uncalib_norm = mult * posts_uncalib / sum_posts_uncalib\n",
    "    if ndim == 3: posts_uncalib_norm = posts_uncalib_norm.squeeze() \n",
    "    return posts_uncalib_norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE = True\n",
    "# posts_uncalib = normalize(posts_uncalib) if NORMALIZE is True else posts_uncalib\n",
    "\n",
    "posts_uncalib_unnorm = posts_uncalib\n",
    "posts_uncalib_norm   = normalize(posts_uncalib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b0acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calibration\n",
    "irc_unnorm = IsotonicRegressionCalibration(posts_uncalib_unnorm, targets)    \n",
    "posts_calib_unnorm = irc_unnorm.calibrate(posts_uncalib_unnorm)\n",
    "# torch.save(posts_calib, os.path.join(logdir, 'posts_calib.pt'))\n",
    "LogIRC(None, irc_unnorm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration\n",
    "irc_norm = IsotonicRegressionCalibration(posts_uncalib_norm, targets)    \n",
    "posts_calib_norm = irc_norm.calibrate(posts_uncalib_norm)\n",
    "# torch.save(posts_calib, os.path.join(logdir, 'posts_calib.pt'))\n",
    "LogIRC(None, irc_norm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d589f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "212fc6df",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# class IsotonicRegressionCalibration():\n",
    "#     def __init__(self, posts_uncalib, targets):\n",
    "# #         super().__init__()\n",
    "#         self.posts_uncalib = posts_uncalib\n",
    "#         self.targets = targets\n",
    "        \n",
    "#         print('initialzing')\n",
    "        \n",
    "#         assert torch.sum(torch.isnan(posts_uncalib.view(-1))).item() == 0\n",
    "        \n",
    "        \n",
    "#         self.post_data_uncalib = PostData(posts_uncalib, targets)\n",
    "    \n",
    "#         self.relicurve_uncalib = self.post_data_uncalib.get_relicurve().cpu()\n",
    "        \n",
    "#         self.ir = self.get_ir(self.relicurve_uncalib, self.post_data_uncalib.alpha_centers.cpu())\n",
    "    \n",
    "    \n",
    "#     def get_ir(self, relicurve, alpha_centers):\n",
    "#         alpha_centers_zero = torch.cat((torch.tensor([0]), alpha_centers))\n",
    "#         relicurve_zero     = torch.cat((torch.tensor([0]), relicurve))\n",
    "\n",
    "#         ir = IsotonicRegression(out_of_bounds = 'clip')\n",
    "        \n",
    "#         ir.fit(alpha_centers_zero, relicurve_zero);\n",
    "#         return ir\n",
    "    \n",
    "#     def calibrate(self, posts):\n",
    "#         posts_calib = self.ir.predict(posts.cpu().flatten()).reshape(posts.shape)\n",
    "#         posts_calib = torch.tensor(posts_calib, device = posts.device, dtype = posts.dtype)\n",
    "#         return posts_calib\n",
    "\n",
    "# class LogIRC:\n",
    "#     def __init__(self, irc):\n",
    "                \n",
    "#         self.posts_uncalib = irc.posts_uncalib\n",
    "#         self.targets = irc.targets\n",
    "#         self.relicurve_uncalib = irc.relicurve_uncalib\n",
    "#         self.alpha_edges = irc.post_data_uncalib.alpha_edges.cpu()\n",
    "#         self.alpha_centers = irc.post_data_uncalib.alpha_centers.cpu()\n",
    "#         self.ir = irc.ir\n",
    "\n",
    "        \n",
    "#         self.posts_calib = irc.calibrate(self.posts_uncalib)\n",
    "#         self.relicurve_calib = PostData(self.posts_calib, self.targets).get_relicurve().cpu()\n",
    "        \n",
    "#     def plot(self):\n",
    "#         fig = plt.figure()\n",
    "#         plt.stairs(self.relicurve_uncalib, self.alpha_edges, label = 'Uncalibrated')\n",
    "#         plt.stairs(self.relicurve_calib, self.alpha_edges, label = 'Calibrated')\n",
    "#         plt.plot(self.alpha_centers, self.ir.predict(self.alpha_centers), label = 'Fit')\n",
    "#         plt.legend(loc = 2)\n",
    "#         plt.plot((0, 1), (0, 1), 'k:')\n",
    "#         plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "irc = IsotonicRegressionCalibration(posts_uncalib, targets)    \n",
    "\n",
    "posts_calib = irc.calibrate(posts_uncalib)\n",
    "torch.save(posts_calib, os.path.join(tbl.experiment.get_logdir(), 'posts_calib.pt'))\n",
    "\n",
    "log_irc = LogIRC(None, irc).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log simulation inference\n",
    "log_post = LogPost(None, posts_calib, targets, fig_kwargs = dict(dpi = 100, figsize = (4,3)), calib = 'calibrated')\n",
    "log_post.plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b305721",
   "metadata": {},
   "source": [
    "# Test with original simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMALIZE = False\n",
    "\n",
    "def get_testdata(simulator, infer, irc, mult, n_test = 4):\n",
    "    test_posts, test_sims = [], []\n",
    "\n",
    "    for _ in range(n_test):\n",
    "        test_sim = simulator.sample(1)\n",
    "\n",
    "        test_post_uncalib = infer.get_post(test_sim).squeeze(0)\n",
    "        test_sim = infer.squeeze_obs(test_sim)\n",
    "        test_post_uncalib = normalize(test_post_uncalib, mult) if NORMALIZE is True else test_post_uncalib\n",
    "        test_post = irc.calibrate(test_post_uncalib)\n",
    "\n",
    "        test_sims.append(test_sim)\n",
    "        test_posts.append(test_post)\n",
    "\n",
    "    test_posts = torch.stack(test_posts)       \n",
    "    \n",
    "    \n",
    "    return test_sims, test_posts\n",
    "\n",
    "def plot_testdata(test_sims, test_posts, zlog = True):\n",
    "    vmax, vmin = test_posts.max(), test_posts.min()\n",
    "    for test_sim, test_post in zip(test_sims, test_posts):\n",
    "#         print(f'Msub = {coord[0,0].item()}')\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax)\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                       **kwargs, \n",
    "                       );\n",
    "test_sims, test_posts = get_testdata(simulator, infer, irc, mult = 1, n_test = 4)\n",
    "plot_testdata(test_sims, test_posts, zlog = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e50be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_sims, test_posts = get_testdata(simulator, infer, irc, mult = 1, n_test = 4)\n",
    "plot_testdata(test_sims, test_posts, zlog = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ff57c",
   "metadata": {},
   "source": [
    "# External simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cd412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ext_post(Infer):\n",
    "    def __init__(self, simulator, network, datamodule, n_ext):\n",
    "        super().__init__(simulator, network, datamodule)\n",
    "        self.simulator = simulator\n",
    "        self.n_ext = n_ext\n",
    "        \n",
    "    def get_uncalib_posts(self):\n",
    "        sims = self.simulator.sample(self.n_ext)\n",
    "        posts, targets = self.get_posts2(sims, max_n_test = self.n_ext)\n",
    "        return posts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sub = 4\n",
    "n_ext = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_simulator = hydra.utils.instantiate(cfg.simulation.model, n_sub = n_sub, part_empty = 0.)\n",
    "ext_infer = Infer(ext_simulator, network, datamodule)\n",
    "\n",
    "ext_sims = ext_simulator.sample(n_ext)\n",
    "ext_posts_uncalib, ext_targets = ext_infer.get_posts2(ext_sims, n_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_posts_uncalib_unnorm = ext_posts_uncalib\n",
    "ext_posts_uncalib_norm   = normalize(ext_posts_uncalib, mult = n_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_irc_unnorm = IsotonicRegressionCalibration(ext_posts_uncalib_unnorm, ext_targets)    \n",
    "ext_posts_calib_unnorm = ext_irc_unnorm.calibrate(ext_posts_uncalib_unnorm)\n",
    "LogIRC(None, ext_irc_unnorm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_irc_norm  = IsotonicRegressionCalibration(ext_posts_uncalib_norm , ext_targets)    \n",
    "ext_posts_calib_norm = ext_irc_norm.calibrate(ext_posts_uncalib_norm)\n",
    "LogIRC(None, ext_irc_norm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744afbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_test_sims, ext_test_posts = get_testdata(ext_simulator, ext_infer, ext_irc_unnorm, mult = n_sub, n_test = 3)\n",
    "plot_testdata(ext_test_sims, ext_test_posts, zlog = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf695c3",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb753888",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts_calib = irc.calibrate(test_posts_uncalib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213d960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts_calib.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c40c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_post = LogPost(None, test_posts_calib, test_targets, fig_kwargs = dict(dpi = 100, figsize = (4,3)), calib = 'calibrated')\n",
    "log_post.plot_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_post(n_test, test_simulator):\n",
    "#     test_sim = test_simulator.sample(n_test)\n",
    "    \n",
    "#     test_post = infer.get_post(test_sim).squeeze(0)\n",
    "#     test_sim = infer.squeeze_obs(test_sim)\n",
    "    \n",
    "#     return test_post, test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testdata(simulator, infer, irc. n_test = 4):\n",
    "    test_posts, test_sims = [], []\n",
    "\n",
    "    for _ in range(n_test):\n",
    "        test_sim = simulator.sample(1)\n",
    "\n",
    "        test_post = infer.get_post(test_sim).squeeze(0)\n",
    "        test_sim = infer.squeeze_obs(test_sim)\n",
    "        test_post = irc.calibrate(test_post_uncalib)\n",
    "\n",
    "        test_sims.append(test_sim)\n",
    "        test_posts.append(test_post)\n",
    "\n",
    "    test_posts = torch.stack(test_posts)       \n",
    "    \n",
    "    \n",
    "    return test_sims, test_posts\n",
    "\n",
    "def plot_testdata(test_sims, test_posts, zlog = True):\n",
    "    vmax, vmin = test_posts.max(), test_posts.min()\n",
    "    for test_sim, test_post in zip(test_sims, test_posts):\n",
    "#         print(f'Msub = {coord[0,0].item()}')\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax)\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                       **kwargs, \n",
    "                       );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c72943d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for zlog in [True]:\n",
    "    for test_sim, test_post in zip(test_sims, test_posts):\n",
    "#         print(f'Msub = {coord[0,0].item()}')\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax)\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                       **kwargs, \n",
    "                       );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0a315",
   "metadata": {},
   "source": [
    "## Mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbcdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_post(mock_z_sub):\n",
    "\n",
    "    mock_simulator = hydra.utils.instantiate(cfg.simulation.model, z_sub_true = mock_z_sub)\n",
    "    mock_sim = infer.unsqueeze_obs(mock_simulator.gen_mock())\n",
    "\n",
    "    mock_post = infer.get_post(mock_sim).squeeze(0)\n",
    "    mock_sim = infer.squeeze_obs(mock_sim)\n",
    "    \n",
    "    return mock_post, mock_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c293d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = torch.tensor([8.5, 9.5, 10.5])\n",
    "xs = torch.linspace(-1.5, 1.5, 1)\n",
    "ys = torch.linspace(0.5, -2., 1)\n",
    "\n",
    "# Ms = torch.tensor([8.5])\n",
    "# xs = torch.linspace(-1.5, 1.5, 3)\n",
    "# ys = torch.linspace(2, -2., 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b180b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_z_sub = torch.tensor([[0., 0., 0.]])\n",
    "mock_post, mock_sim = get_mock_post(mock_z_sub)\n",
    "\n",
    "mock_posts, mock_sims, coords = [mock_post], [mock_sim], [mock_z_sub]\n",
    "M = Ms[0]\n",
    "for M in tqdm(Ms):\n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            mock_z_sub = torch.tensor([[M, x, y]])\n",
    "            mock_post, mock_sim = get_mock_post(mock_z_sub)\n",
    "            mock_posts.append(mock_post)\n",
    "            mock_sims.append(mock_sim)\n",
    "            coords.append(mock_z_sub)\n",
    "mock_posts = torch.stack(mock_posts)       \n",
    "coords = torch.stack(coords)       \n",
    "vmax, vmin = mock_posts.max(), mock_posts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573277a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_trues = [False] + [True]*(len(mock_posts)-1)\n",
    "\n",
    "for zlog in [False, True]:\n",
    "    for mock_sim, mock_post, coord, plot_true in zip(mock_sims, mock_posts, coords, plot_trues):\n",
    "#         print(f'Msub = {coord[0,0].item()}')\n",
    "        logobs = LogObs(None, mock_sim, mock_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax)\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = plot_true,\n",
    "                        title = rf'Sum posterios $= {torch.sum(mock_post).item():.2f}$, $M_{{ \\rm{{sub}} }} = {coord[0,0].item():.2f}$',\n",
    "#                         title = rf'$M_{{ \\rm{{sub}} }} = {coord[0,0].item():.2f}$',\n",
    "                       **kwargs, \n",
    "                       );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969f36d",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_post(n_test, test_simulator):\n",
    "    test_sim = test_simulator.sample(n_test)\n",
    "    \n",
    "    test_post = infer.get_post(test_sim).squeeze(0)\n",
    "    test_sim = infer.squeeze_obs(test_sim)\n",
    "    \n",
    "    return test_post, test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ea99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_post(n_test, n_sub_test):\n",
    "    test_simulator = hydra.utils.instantiate(cfg.simulation.model, n_sub = n_sub_test, part_empty = 0.)\n",
    "    test_sim = test_simulator.sample(n_test)\n",
    "    \n",
    "    test_post = infer.get_post(test_sim).squeeze(0)\n",
    "    test_sim = infer.squeeze_obs(test_sim)\n",
    "    \n",
    "    return test_post, test_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts, test_sims, coords = [], [], []\n",
    "\n",
    "for _ in range(7):\n",
    "    test_post, test_sim = get_test_post(n_test = 1, n_sub_test = 4)\n",
    "\n",
    "    test_posts.append(test_post)\n",
    "    test_sims.append(test_sim)\n",
    "    coords.append(test_sim['z_sub'])\n",
    "test_posts = torch.stack(test_posts)       \n",
    "coords = torch.stack(coords)       \n",
    "vmax, vmin = test_posts.max(), test_posts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5297b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for zlog in [True]:\n",
    "    for test_sim, test_post, coord in zip(test_sims, test_posts, coords):\n",
    "#         print(f'Msub = {coord[0,0].item()}')\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax)\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                       **kwargs, \n",
    "                       );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48627dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88470639",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787507ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simulator = hydra.utils.instantiate(cfg.simulation.model, n_sub = 4, part_empty = 0.)\n",
    "test_sim = test_simulator.sample(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts, test_targets = infer.get_posts2(test_sim, max_n_test = 10_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_post = LogPost(None, test_posts, test_targets, fig_kwargs = dict(dpi = 100, figsize = (4, 3)) )\n",
    "log_post.plot_relicurve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c8fdb",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alpha = 50\n",
    "post_data = PostData(test_posts, test_targets, n_alpha = n_alpha)\n",
    "\n",
    "alpha_edges, alpha_centers = post_data.get_alpha(n_alpha = n_alpha)\n",
    "alpha_edges, alpha_centers = alpha_edges.cpu(), alpha_centers.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relicurve = post_data.get_relicurve(n_alpha = n_alpha).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5dcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cir.calibrate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cce8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea6ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_centers_zero = torch.cat((torch.tensor([0]), alpha_centers))\n",
    "relicurve_zero     = torch.cat((torch.tensor([0]), relicurve))\n",
    "\n",
    "ir = IsotonicRegression(out_of_bounds = 'clip')\n",
    "ir.fit(alpha_centers_zero, relicurve_zero);\n",
    "\n",
    "relicurve_ir = ir.predict(alpha_centers)\n",
    "\n",
    "plt.stairs(relicurve, alpha_edges)\n",
    "plt.plot(alpha_centers, relicurve_ir )\n",
    "plt.plot((0, 1), (0, 1), 'k:')\n",
    "\n",
    "relicurve_ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0bdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_calib = calibrate(test_posts, ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_post = LogPost(None, posts_calib, test_targets, fig_kwargs = dict(dpi = 100, figsize = (4, 3)) )\n",
    "log_post.plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb6eb0",
   "metadata": {},
   "source": [
    "## Plotting after calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_posts_calib, test_sims_calib, coords_calib = [], [], []\n",
    "\n",
    "for _ in range(4):\n",
    "    test_post_calib, test_sim_calib = get_test_post(n_test = 1, n_sub_test = 4)\n",
    "    test_post_calib = calibrate(test_post_calib, ir)\n",
    "\n",
    "    test_posts_calib.append(test_post_calib)\n",
    "    test_sims_calib.append(test_sim_calib)\n",
    "    coords_calib.append(test_sim_calib['z_sub'])\n",
    "test_posts_calib = torch.stack(test_posts_calib)       \n",
    "coords_calib = torch.stack(coords_calib)       \n",
    "vmax, vmin = test_posts_calib.max(), test_posts_calib.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd547003",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for zlog in [True]:\n",
    "    for test_sim, test_post, coord in zip(test_sims_calib, test_posts_calib, coords_calib):\n",
    "#         print(f'Msub = {coord[0,0].item()}')\n",
    "        logobs = LogObs(None, test_sim, test_post, prior, grid_coords)\n",
    "        kwargs = dict(vmin = vmin, vmax = vmax)\n",
    "\n",
    "        logobs.plot_msc(zlog = zlog, \n",
    "                        plot_true = True,\n",
    "                        title = rf'Sum posterios $= {torch.sum(test_post).item():.2f}$',\n",
    "                       **kwargs, \n",
    "                       );\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
